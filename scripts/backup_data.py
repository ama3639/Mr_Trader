#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ MrTrader Bot
"""
import os
import sys
import shutil
import sqlite3
import zipfile
import json
from pathlib import Path
from datetime import datetime, timedelta
import argparse
import logging

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÙˆØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.config import Config
from utils.logger import logger


class BackupManager:
    """Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ú©Ø§Ù¾"""
    
    def __init__(self):
        self.project_root = project_root
        self.backup_dir = self.project_root / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        
        # ØªÙ†Ø¸ÛŒÙ… Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ú©Ø§Ù¾
        self.daily_dir = self.backup_dir / "daily"
        self.weekly_dir = self.backup_dir / "weekly"
        self.monthly_dir = self.backup_dir / "monthly"
        
        for dir_path in [self.daily_dir, self.weekly_dir, self.monthly_dir]:
            dir_path.mkdir(exist_ok=True)
    
    def create_backup(self, backup_type="manual", include_logs=False):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ø§Ù¾ Ú©Ø§Ù…Ù„"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ØªØ¹ÛŒÛŒÙ† Ù¾ÙˆØ´Ù‡ Ø¨Ú©Ø§Ù¾ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
            if backup_type == "daily":
                backup_folder = self.daily_dir
            elif backup_type == "weekly":
                backup_folder = self.weekly_dir
            elif backup_type == "monthly":
                backup_folder = self.monthly_dir
            else:
                backup_folder = self.backup_dir
            
            backup_name = f"mrtrader_backup_{backup_type}_{timestamp}"
            backup_path = backup_folder / f"{backup_name}.zip"
            
            print(f"ğŸ”„ Ø´Ø±ÙˆØ¹ Ø¨Ú©Ø§Ù¾ {backup_type}...")
            
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # Ø¨Ú©Ø§Ù¾ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
                self._backup_database(zipf)
                
                # Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV
                self._backup_csv_files(zipf)
                
                # Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
                self._backup_config_files(zipf)
                
                # Ø¨Ú©Ø§Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§ (Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª)
                if include_logs:
                    self._backup_logs(zipf)
                
                # Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ù¾Ø±ÙˆÚ˜Ù‡
                self._backup_project_files(zipf)
                
                # Ø§ÛŒØ¬Ø§Ø¯ manifest
                self._create_manifest(zipf, backup_type, timestamp)
            
            # Ø§ÛŒØ¬Ø§Ø¯ checksum
            checksum = self._calculate_checksum(backup_path)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ú©Ø§Ù¾
            backup_info = {
                'backup_name': backup_name,
                'backup_type': backup_type,
                'timestamp': timestamp,
                'file_path': str(backup_path),
                'file_size': backup_path.stat().st_size,
                'checksum': checksum,
                'created_at': datetime.now().isoformat()
            }
            
            self._save_backup_info(backup_info)
            
            print(f"âœ… Ø¨Ú©Ø§Ù¾ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {backup_path}")
            print(f"ğŸ“¦ Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {self._format_size(backup_path.stat().st_size)}")
            print(f"ğŸ”’ Checksum: {checksum}")
            
            return backup_path
            
        except Exception as e:
            logger.error(f"Error creating backup: {e}")
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ø§Ù¾: {e}")
            raise
    
    def _backup_database(self, zipf):
        """Ø¨Ú©Ø§Ù¾ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"""
        try:
            db_path = Config.DATABASE_PATH
            if db_path.exists():
                zipf.write(db_path, "database/mrtrader.db")
                print("âœ… Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ú©Ø§Ù¾ Ø´Ø¯")
            
            # Ø¨Ú©Ø§Ù¾ WAL Ùˆ SHM files Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
            for ext in ['.wal', '.shm']:
                wal_file = Path(str(db_path) + ext)
                if wal_file.exists():
                    zipf.write(wal_file, f"database/{wal_file.name}")
                    
        except Exception as e:
            logger.error(f"Error backing up database: {e}")
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡: {e}")
    
    def _backup_csv_files(self, zipf):
        """Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV"""
        try:
            data_dir = self.project_root / "data"
            if data_dir.exists():
                for csv_file in data_dir.glob("*.csv"):
                    zipf.write(csv_file, f"data/{csv_file.name}")
                print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø¨Ú©Ø§Ù¾ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Error backing up CSV files: {e}")
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV: {e}")
    
    def _backup_config_files(self, zipf):
        """Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª"""
        try:
            config_dir = self.project_root / "config"
            if config_dir.exists():
                for config_file in config_dir.glob("*.json"):
                    zipf.write(config_file, f"config/{config_file.name}")
                print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ú©Ø§Ù¾ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Error backing up config files: {e}")
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {e}")
    
    def _backup_logs(self, zipf):
        """Ø¨Ú©Ø§Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§"""
        try:
            logs_dir = self.project_root / "logs"
            if logs_dir.exists():
                # ÙÙ‚Ø· Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
                cutoff_date = datetime.now() - timedelta(days=7)
                
                for log_file in logs_dir.glob("*.log"):
                    if datetime.fromtimestamp(log_file.stat().st_mtime) > cutoff_date:
                        zipf.write(log_file, f"logs/{log_file.name}")
                print("âœ… Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¨Ú©Ø§Ù¾ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Error backing up logs: {e}")
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§: {e}")
    
    def _backup_project_files(self, zipf):
        """Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ù¾Ø±ÙˆÚ˜Ù‡"""
        try:
            important_files = [
                "requirements.txt",
                "main.py",
                ".env.example"
            ]
            
            for file_name in important_files:
                file_path = self.project_root / file_name
                if file_path.exists():
                    zipf.write(file_path, f"project/{file_name}")
            
            print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ú©Ø§Ù¾ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Error backing up project files: {e}")
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡: {e}")
    
    def _create_manifest(self, zipf, backup_type, timestamp):
        """Ø§ÛŒØ¬Ø§Ø¯ manifest Ø¨Ú©Ø§Ù¾"""
        try:
            manifest = {
                'backup_info': {
                    'type': backup_type,
                    'timestamp': timestamp,
                    'created_at': datetime.now().isoformat(),
                    'version': getattr(Config, 'BOT_VERSION', '1.0.0')
                },
                'contents': {
                    'database': 'database/mrtrader.db',
                    'csv_files': 'data/',
                    'config_files': 'config/',
                    'project_files': 'project/'
                },
                'restore_instructions': [
                    '1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ Ù…Ù†Ø§Ø³Ø¨',
                    '2. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø² database/mrtrader.db',
                    '3. Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ data/',
                    '4. Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² config/',
                    '5. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¬Ø¯Ø¯ Ø±Ø¨Ø§Øª'
                ]
            }
            
            manifest_json = json.dumps(manifest, indent=2, ensure_ascii=False)
            zipf.writestr("MANIFEST.json", manifest_json)
            
        except Exception as e:
            logger.error(f"Error creating manifest: {e}")
    
    def _calculate_checksum(self, file_path):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ checksum ÙØ§ÛŒÙ„"""
        try:
            import hashlib
            
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            
            return hash_md5.hexdigest()
            
        except Exception as e:
            logger.error(f"Error calculating checksum: {e}")
            return None
    
    def _save_backup_info(self, backup_info):
        """Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ú©Ø§Ù¾"""
        try:
            backup_log_file = self.backup_dir / "backup_log.json"
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§Ú¯ Ù…ÙˆØ¬ÙˆØ¯
            if backup_log_file.exists():
                with open(backup_log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            else:
                logs = []
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ú©Ø§Ù¾ Ø¬Ø¯ÛŒØ¯
            logs.append(backup_info)
            
            # Ø­ÙØ¸ ÙÙ‚Ø· 50 Ø±Ú©ÙˆØ±Ø¯ Ø¢Ø®Ø±
            logs = logs[-50:]
            
            # Ø°Ø®ÛŒØ±Ù‡
            with open(backup_log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"Error saving backup info: {e}")
    
    def _format_size(self, size_bytes):
        """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ§ÛŒÙ„"""
        if size_bytes >= 1024**3:
            return f"{size_bytes / (1024**3):.2f} GB"
        elif size_bytes >= 1024**2:
            return f"{size_bytes / (1024**2):.2f} MB"
        elif size_bytes >= 1024:
            return f"{size_bytes / 1024:.2f} KB"
        else:
            return f"{size_bytes} bytes"
    
    def cleanup_old_backups(self, keep_daily=7, keep_weekly=4, keep_monthly=12):
        """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¨Ú©Ø§Ù¾â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        try:
            print("ğŸ§¹ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¨Ú©Ø§Ù¾â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ...")
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ
            cleanup_rules = [
                (self.daily_dir, keep_daily, "Ø±ÙˆØ²Ø§Ù†Ù‡"),
                (self.weekly_dir, keep_weekly, "Ù‡ÙØªÚ¯ÛŒ"), 
                (self.monthly_dir, keep_monthly, "Ù…Ø§Ù‡Ø§Ù†Ù‡")
            ]
            
            total_deleted = 0
            total_size_freed = 0
            
            for backup_dir, keep_count, backup_type in cleanup_rules:
                if not backup_dir.exists():
                    continue
                
                # Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ú©Ø§Ù¾ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®
                backup_files = sorted(
                    [f for f in backup_dir.glob("*.zip")],
                    key=lambda x: x.stat().st_mtime,
                    reverse=True
                )
                
                # Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
                files_to_delete = backup_files[keep_count:]
                
                for file_path in files_to_delete:
                    file_size = file_path.stat().st_size
                    file_path.unlink()
                    total_deleted += 1
                    total_size_freed += file_size
                    print(f"ğŸ—‘ï¸ Ø­Ø°Ù Ø´Ø¯: {file_path.name}")
            
            if total_deleted > 0:
                print(f"âœ… {total_deleted} ÙØ§ÛŒÙ„ Ø­Ø°Ù Ø´Ø¯ØŒ {self._format_size(total_size_freed)} ÙØ¶Ø§ Ø¢Ø²Ø§Ø¯ Ø´Ø¯")
            else:
                print("âœ… Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù†ÛŒØ³Øª")
                
        except Exception as e:
            logger.error(f"Error cleaning up backups: {e}")
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ: {e}")
    
    def list_backups(self):
        """Ù„ÛŒØ³Øª Ø¨Ú©Ø§Ù¾â€ŒÙ‡Ø§"""
        try:
            print("ğŸ“‹ Ù„ÛŒØ³Øª Ø¨Ú©Ø§Ù¾â€ŒÙ‡Ø§:")
            
            backup_dirs = [
                (self.daily_dir, "Ø±ÙˆØ²Ø§Ù†Ù‡"),
                (self.weekly_dir, "Ù‡ÙØªÚ¯ÛŒ"),
                (self.monthly_dir, "Ù…Ø§Ù‡Ø§Ù†Ù‡"),
                (self.backup_dir, "Ø¯Ø³ØªÛŒ")
            ]
            
            total_size = 0
            total_count = 0
            
            for backup_dir, backup_type in backup_dirs:
                if not backup_dir.exists():
                    continue
                
                backup_files = list(backup_dir.glob("*.zip"))
                if not backup_files:
                    continue
                
                print(f"\nğŸ“ {backup_type}:")
                
                for backup_file in sorted(backup_files, key=lambda x: x.stat().st_mtime, reverse=True):
                    size = backup_file.stat().st_size
                    mtime = datetime.fromtimestamp(backup_file.stat().st_mtime)
                    
                    print(f"  â€¢ {backup_file.name}")
                    print(f"    ğŸ“… {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"    ğŸ“¦ {self._format_size(size)}")
                    
                    total_size += size
                    total_count += 1
            
            print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡: {total_count} Ø¨Ú©Ø§Ù¾ØŒ {self._format_size(total_size)} Ø­Ø¬Ù… Ú©Ù„")
            
        except Exception as e:
            logger.error(f"Error listing backups: {e}")
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÛŒØ³Øª Ø¨Ú©Ø§Ù¾â€ŒÙ‡Ø§: {e}")
    
    def restore_backup(self, backup_path):
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ø¨Ú©Ø§Ù¾"""
        try:
            backup_path = Path(backup_path)
            if not backup_path.exists():
                print(f"âŒ ÙØ§ÛŒÙ„ Ø¨Ú©Ø§Ù¾ ÛŒØ§ÙØª Ù†Ø´Ø¯: {backup_path}")
                return False
            
            print(f"ğŸ”„ Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø²: {backup_path.name}")
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ø§Ù¾ ÙØ¹Ù„ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
            print("ğŸ“¦ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ø§Ù¾ Ø§ÛŒÙ…Ù†ÛŒ...")
            safety_backup = self.create_backup("safety_restore", include_logs=False)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ú©Ø§Ù¾
            with zipfile.ZipFile(backup_path, 'r') as zipf:
                # Ø¨Ø±Ø±Ø³ÛŒ manifest
                try:
                    manifest_content = zipf.read("MANIFEST.json")
                    manifest = json.loads(manifest_content)
                    print(f"ğŸ“‹ Ø¨Ú©Ø§Ù¾ Ù†ÙˆØ¹ {manifest['backup_info']['type']} Ø§Ø² ØªØ§Ø±ÛŒØ® {manifest['backup_info']['timestamp']}")
                except:
                    print("âš ï¸ Manifest ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ...")
                
                # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡
                try:
                    db_data = zipf.read("database/mrtrader.db")
                    with open(Config.DATABASE_PATH, 'wb') as f:
                        f.write(db_data)
                    print("âœ… Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯")
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡: {e}")
                
                # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV
                data_dir = self.project_root / "data"
                data_dir.mkdir(exist_ok=True)
                
                for file_info in zipf.filelist:
                    if file_info.filename.startswith("data/") and file_info.filename.endswith(".csv"):
                        zipf.extract(file_info, self.project_root)
                        print(f"âœ… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯: {file_info.filename}")
            
            print("âœ… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
            print(f"ğŸ›¡ï¸ Ø¨Ú©Ø§Ù¾ Ø§ÛŒÙ…Ù†ÛŒ: {safety_backup}")
            return True
            
        except Exception as e:
            logger.error(f"Error restoring backup: {e}")
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ: {e}")
            return False


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    parser = argparse.ArgumentParser(description="Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ú©Ø§Ù¾ MrTrader Bot")
    parser.add_argument("action", choices=["create", "list", "cleanup", "restore"],
                       help="Ø¹Ù…Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±")
    parser.add_argument("--type", default="manual", choices=["daily", "weekly", "monthly", "manual"],
                       help="Ù†ÙˆØ¹ Ø¨Ú©Ø§Ù¾")
    parser.add_argument("--include-logs", action="store_true",
                       help="Ø´Ø§Ù…Ù„ Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¯Ø± Ø¨Ú©Ø§Ù¾")
    parser.add_argument("--backup-path", 
                       help="Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¨Ú©Ø§Ù¾ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ")
    
    args = parser.parse_args()
    
    try:
        backup_manager = BackupManager()
        
        if args.action == "create":
            backup_manager.create_backup(args.type, args.include_logs)
        
        elif args.action == "list":
            backup_manager.list_backups()
        
        elif args.action == "cleanup":
            backup_manager.cleanup_old_backups()
        
        elif args.action == "restore":
            if not args.backup_path:
                print("âŒ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¨Ú©Ø§Ù¾ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ (--backup-path)")
                return False
            
            backup_manager.restore_backup(args.backup_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)