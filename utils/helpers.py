"""
Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ - ØªÙˆØ§Ø¨Ø¹ Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ
Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ Parser Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒâ€ŒÙ…Ø­ÙˆØ± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
"""

import re
import json
import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional, Union, Tuple
from datetime import datetime, timedelta
import asyncio
from functools import wraps
import time

# =========================
# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Parser Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
# =========================

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ patterns Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ù‡Ù…Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§
EXTRACTION_PATTERNS = {
    # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª - Ø§Ø² Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ù‡ Ø®Ø§Øµ
    "price_patterns": [
        r"Ù‚ÛŒÙ…Øª Ù„Ø§ÛŒÙˆ[:\s]*([0-9,]+\.?[0-9]*)",
        r"Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª[:\s]*([0-9,]+\.?[0-9]*)", 
        r"Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ[:\s]*([0-9,]+\.?[0-9]*)",
        r"Ù‚ÛŒÙ…Øª Ø¢Ø®Ø±[:\s]*([0-9,]+\.?[0-9]*)",
        r"Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù†[:\s]*([0-9,]+\.?[0-9]*)",
        r"Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù†[:\s]*([0-9,]+\.?[0-9]*)"
    ],
    
    # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„ - Ú†Ù†Ø¯ÛŒÙ† pattern Ø¨Ø§ mapping
    "signal_patterns": [
        {
            "pattern": r"Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ ØªØ­Ù„ÛŒÙ„[:\s]*([^\n]+)",
            "mapping": {
                r"Ø³ÛŒÚ¯Ù†Ø§Ù„ ØµØ¹ÙˆØ¯ÛŒ|BUY": "Ø®Ø±ÛŒØ¯",
                r"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ø²ÙˆÙ„ÛŒ|SELL": "ÙØ±ÙˆØ´", 
                r"HOLD|Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ|ØªØ¹Ø§Ø¯Ù„": "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ"
            }
        },
        {
            "pattern": r"Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„[:\s]*([A-Z_]+)",
            "mapping": {
                r"SELL_DIVERGENCE|STRONG_SELL": "ÙØ±ÙˆØ´",
                r"BUY_DIVERGENCE|STRONG_BUY": "Ø®Ø±ÛŒØ¯",
                r"HOLD": "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ"
            }
        },
        {
            "pattern": r"ÙØ±ØµØª\s+(\w+)\s+Ù…Ù†Ø§Ø³Ø¨",
            "mapping": {
                r"ÙØ±ÙˆØ´": "ÙØ±ÙˆØ´",
                r"Ø®Ø±ÛŒØ¯": "Ø®Ø±ÛŒØ¯"
            }
        },
        {
            "pattern": r"Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„[:\s]*([^\n]+)",
            "mapping": {
                r"STRONG SELL|Ù‚ÙˆÛŒ.*ÙØ±ÙˆØ´": "ÙØ±ÙˆØ´",
                r"STRONG BUY|Ù‚ÙˆÛŒ.*Ø®Ø±ÛŒØ¯": "Ø®Ø±ÛŒØ¯",
                r"SELL": "ÙØ±ÙˆØ´",
                r"BUY": "Ø®Ø±ÛŒØ¯"
            }
        }
    ],
    
    # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„
    "strength_patterns": [
        {
            "pattern": r"Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„[:\s]*([^\n]+)",
            "mapping": {
                r"STRONG|Ù‚ÙˆÛŒ|Ø¨Ø³ÛŒØ§Ø±": "Ù‚ÙˆÛŒ",
                r"WEAK|Ø¶Ø¹ÛŒÙ": "Ø¶Ø¹ÛŒÙ",
                r"Ù…ØªÙˆØ³Ø·|MEDIUM": "Ù…ØªÙˆØ³Ø·"
            }
        },
        {
            "pattern": r"Ù‚Ø¯Ø±Øª[:\s]*([^)]+)",
            "mapping": {
                r"Ù‚ÙˆÛŒ|STRONG": "Ù‚ÙˆÛŒ",
                r"Ø¶Ø¹ÛŒÙ|WEAK": "Ø¶Ø¹ÛŒÙ",
                r"Ù…ØªÙˆØ³Ø·": "Ù…ØªÙˆØ³Ø·"
            }
        }
    ],
    
    # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø·ÙˆØ­ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ
    "trading_levels": {
        "entry_price": [
            r"Entry[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯[:\s]*([0-9,]+\.?[0-9]*)"
        ],
        "stop_loss": [
            r"SL[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ø­Ø¯ Ø¶Ø±Ø±[:\s]*([0-9,]+\.?[0-9]*)",
            r"stop\s*loss[:\s]*([0-9,]+\.?[0-9]*)"
        ],
        "take_profit": [
            r"TP[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ù‡Ø¯Ù Ù‚ÛŒÙ…ØªÛŒ[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ø­Ø¯ Ø³ÙˆØ¯[:\s]*([0-9,]+\.?[0-9]*)",
            r"take\s*profit[:\s]*([0-9,]+\.?[0-9]*)"
        ],
        "support": [
            r"Ø³Ø·Ø­ Ø­Ù…Ø§ÛŒØª[^:]*[:\s]*([0-9,]+\.?[0-9]*)",
            r"Support[^:]*[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ø­Ù…Ø§ÛŒØª[^:]*[:\s]*([0-9,]+\.?[0-9]*)"
        ],
        "resistance": [
            r"Ø³Ø·Ø­ Ù…Ù‚Ø§ÙˆÙ…Øª[^:]*[:\s]*([0-9,]+\.?[0-9]*)",
            r"Resistance[^:]*[:\s]*([0-9,]+\.?[0-9]*)",
            r"Ù…Ù‚Ø§ÙˆÙ…Øª[^:]*[:\s]*([0-9,]+\.?[0-9]*)"
        ]
    }
}

# =========================
# ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„
# =========================

def extract_signal_details(analysis_result: Dict[str, Any]) -> Dict[str, Any]:
    """
    Parser Ø¬Ø§Ù…Ø¹ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø§Ø² Ù‡Ø± Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø¯
    """
    try:
        from utils.logger import logger
        
        details = {
            "signal_direction": "Ù†Ø§Ù…Ø´Ø®Øµ",
            "strength": "Ù…ØªÙˆØ³Ø·", 
            "confidence": 0.5,
            "current_price": 0.0,
            "entry_price": 0.0,
            "stop_loss": 0.0,
            "take_profit": 0.0,
            "support": 0.0,
            "resistance": 0.0
        }
        
        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² structured data (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        if "analysis" in analysis_result and isinstance(analysis_result["analysis"], dict):
            details.update(_extract_from_structured_data(analysis_result["analysis"]))
        
        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ
        text_content = analysis_result.get("analysis_text") or analysis_result.get("raw_report", "")
        
        if text_content:
            details.update(_extract_from_text_universal(text_content))
        
        # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø§Ø² ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        if details["current_price"] == 0.0:
            details["current_price"] = _extract_price_from_fields(analysis_result)
        
        # 4. Ù…Ø­Ø§Ø³Ø¨Ù‡ confidence
        details["confidence"] = _calculate_confidence(details["strength"])
        
        # 5. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ fallback
        _calculate_fallback_levels(details)
        
        return details
        
    except Exception as e:
        try:
            from utils.logger import logger
            logger.error(f"Error extracting signal details: {e}")
        except:
            print(f"Error extracting signal details: {e}")
        return _get_default_details()

def _extract_from_structured_data(analysis_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ JSON"""
    details = {}
    
    # Ù‚ÛŒÙ…Øª
    if "last_price" in analysis_data:
        details["current_price"] = float(analysis_data["last_price"])
    
    # Ø³ÛŒÚ¯Ù†Ø§Ù„
    if "signal" in analysis_data:
        signal_mapping = {
            "BUY": "Ø®Ø±ÛŒØ¯", "SELL": "ÙØ±ÙˆØ´", "HOLD": "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ",
            "Ø®Ø±ÛŒØ¯": "Ø®Ø±ÛŒØ¯", "ÙØ±ÙˆØ´": "ÙØ±ÙˆØ´", "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ": "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ"
        }
        details["signal_direction"] = signal_mapping.get(
            str(analysis_data["signal"]).upper(), "Ù†Ø§Ù…Ø´Ø®Øµ"
        )
    
    # Ù‚Ø¯Ø±Øª
    if "signal_strength" in analysis_data:
        details["strength"] = str(analysis_data["signal_strength"])
    
    return details

def _extract_from_text_universal(text: str) -> Dict[str, Any]:
    """Parser Ø¬Ø§Ù…Ø¹ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± patterns Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù…ØªÙˆÙ†"""
    details = {}
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
    for pattern in EXTRACTION_PATTERNS["price_patterns"]:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            details["current_price"] = float(match.group(1).replace(',', ''))
            break
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³ÛŒÚ¯Ù†Ø§Ù„
    for signal_config in EXTRACTION_PATTERNS["signal_patterns"]:
        match = re.search(signal_config["pattern"], text, re.IGNORECASE)
        if match:
            matched_text = match.group(1).strip() if match.groups() else match.group(0).strip()
            
            for pattern_key, signal_value in signal_config["mapping"].items():
                if re.search(pattern_key, matched_text, re.IGNORECASE):
                    details["signal_direction"] = signal_value
                    break
            
            if "signal_direction" in details:
                break
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø¯Ø±Øª
    for strength_config in EXTRACTION_PATTERNS["strength_patterns"]:
        match = re.search(strength_config["pattern"], text, re.IGNORECASE)
        if match:
            matched_text = match.group(1).strip()
            
            for pattern_key, strength_value in strength_config["mapping"].items():
                if re.search(pattern_key, matched_text, re.IGNORECASE):
                    details["strength"] = strength_value
                    break
            
            if "strength" in details:
                break
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø·ÙˆØ­ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ
    for level_name, patterns in EXTRACTION_PATTERNS["trading_levels"].items():
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                details[level_name] = float(match.group(1).replace(',', ''))
                break
        
        # Ø§Ú¯Ø± Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø¨Ù‡ pattern Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ùˆ
        if level_name in details:
            continue
    
    return details

def _extract_price_from_fields(analysis_result: Dict[str, Any]) -> float:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø§Ø² ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù"""
    price_fields = ["current_price", "price", "close", "last_price"]
    
    for field in price_fields:
        if field in analysis_result:
            try:
                return float(analysis_result[field])
            except (ValueError, TypeError):
                continue
    
    return 0.0

def _calculate_confidence(strength: str) -> float:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚Ø¯Ø±Øª"""
    confidence_map = {
        "Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ": 0.9,
        "Ù‚ÙˆÛŒ": 0.8, 
        "Ù…ØªÙˆØ³Ø·": 0.6,
        "Ø¶Ø¹ÛŒÙ": 0.4,
        "Ø®ÛŒÙ„ÛŒ Ø¶Ø¹ÛŒÙ": 0.2
    }
    
    for key, value in confidence_map.items():
        if key in strength:
            return value
    
    return 0.5

def _calculate_fallback_levels(details: Dict[str, Any]) -> None:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·ÙˆØ­ fallback Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ"""
    current_price = details.get("current_price", 0.0)
    
    if current_price <= 0:
        return
    
    # Entry price fallback
    if details.get("entry_price", 0.0) == 0.0:
        details["entry_price"] = current_price
    
    entry_price = details["entry_price"]
    signal_direction = details.get("signal_direction", "Ù†Ø§Ù…Ø´Ø®Øµ")
    
    # Stop Loss fallback
    if details.get("stop_loss", 0.0) == 0.0:
        if signal_direction == "ÙØ±ÙˆØ´":
            details["stop_loss"] = entry_price * 1.02  # 2% Ø¨Ø§Ù„Ø§ØªØ±
        else:
            details["stop_loss"] = entry_price * 0.98  # 2% Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
    
    # Take Profit fallback  
    if details.get("take_profit", 0.0) == 0.0:
        if signal_direction == "ÙØ±ÙˆØ´":
            details["take_profit"] = entry_price * 0.97  # 3% Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
        else:
            details["take_profit"] = entry_price * 1.03  # 3% Ø¨Ø§Ù„Ø§ØªØ±
    
    # Support/Resistance fallback
    if details.get("support", 0.0) == 0.0:
        details["support"] = current_price * 0.995  # 0.5% Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±
    
    if details.get("resistance", 0.0) == 0.0:
        details["resistance"] = current_price * 1.005  # 0.5% Ø¨Ø§Ù„Ø§ØªØ±

def _get_default_details() -> Dict[str, Any]:
    """Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
    return {
        "signal_direction": "Ù†Ø§Ù…Ø´Ø®Øµ",
        "strength": "Ù…ØªÙˆØ³Ø·",
        "confidence": 0.5,
        "current_price": 0.0,
        "entry_price": 0.0,
        "stop_loss": 0.0,
        "take_profit": 0.0,
        "support": 0.0,
        "resistance": 0.0
    }

# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† patterns Ø¬Ø¯ÛŒØ¯
def add_extraction_pattern(category: str, pattern: str, mapping: Dict[str, str] = None):
    """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† pattern Ø¬Ø¯ÛŒØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ú©Ø¯"""
    if category == "price":
        EXTRACTION_PATTERNS["price_patterns"].append(pattern)
    elif category == "signal":
        EXTRACTION_PATTERNS["signal_patterns"].append({
            "pattern": pattern,
            "mapping": mapping or {}
        })
    elif category == "strength":
        EXTRACTION_PATTERNS["strength_patterns"].append({
            "pattern": pattern, 
            "mapping": mapping or {}
        })
    elif category in EXTRACTION_PATTERNS["trading_levels"]:
        EXTRACTION_PATTERNS["trading_levels"][category].append(pattern)

def format_signal_message(signal_details: Dict[str, Any], symbol: str, currency: str, timeframe: str, strategy: str) -> str:
    """
    ÙØ±Ù…Øª Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª
    """
    try:
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÛŒÚ¯Ù†Ø§Ù„
        signal_emojis = {
            "Ø®Ø±ÛŒØ¯": "ğŸŸ¢â¬†ï¸",
            "ÙØ±ÙˆØ´": "ğŸ”´â¬‡ï¸", 
            "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ": "ğŸŸ¡â¸ï¸",
            "Ù†Ø§Ù…Ø´Ø®Øµ": "âšª"
        }
        
        signal_direction = signal_details.get("signal_direction", "Ù†Ø§Ù…Ø´Ø®Øµ")
        emoji = signal_emojis.get(signal_direction, "âšª")
        current_price = signal_details.get("current_price", 0.0)
        
        # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø§ØµÙ„ÛŒ
        message = f"ğŸ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ {symbol}/{currency}\n"
        message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        message += "ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ:\n"
        message += f"â± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {timeframe}\n"
        message += f"ğŸ’µ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ: {current_price:,.4f} {currency}\n"
        message += f"ğŸ•’ Ø²Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„: 1404/06/15 - 04:27:29\n"
        message += f"{emoji} Ø³ÛŒÚ¯Ù†Ø§Ù„: {signal_direction}\n"
        message += f"ğŸ‘Œ Ù‚Ø¯Ø±Øª: {signal_details.get('strength', 'Ù…ØªÙˆØ³Ø·')}\n"
        
        # Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ
        message += "ğŸ’° Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ:\n"
        entry_price = signal_details.get("entry_price", current_price)
        stop_loss = signal_details.get("stop_loss", 0.0)
        take_profit = signal_details.get("take_profit", 0.0)
        
        message += f"ğŸ¯ Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯: {entry_price:,.4f}\n"
        message += f"ğŸ›‘ Ø­Ø¯ Ø¶Ø±Ø±: {stop_loss:,.4f}\n"
        message += f"ğŸ’ Ù‡Ø¯Ù Ù‚ÛŒÙ…ØªÛŒ: {take_profit:,.4f}\n"
        
        # ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
        message += "ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„:\n"
        support = signal_details.get("support", 0.0)
        resistance = signal_details.get("resistance", 0.0)
        confidence = signal_details.get("confidence", 0.5)
        
        message += f"ğŸ”» Ø­Ù…Ø§ÛŒØª: {support:,.4f}\n"
        message += f"ğŸ”º Ù…Ù‚Ø§ÙˆÙ…Øª: {resistance:,.4f}\n"
        message += f"ğŸ“Š Ø§Ø¹ØªÙ…Ø§Ø¯: {confidence:.0%}\n"
        
        # ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ
        message += "\nâš ï¸ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ù…Ù‡Ù…: Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ ØµØ±ÙØ§Ù‹ Ø¬Ù†Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ ØªÙˆØµÛŒÙ‡ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ø³ÙˆØ¨ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯."
        
        return message
        
    except Exception as e:
        try:
            from utils.logger import logger
            logger.error(f"Error formatting signal message: {e}")
        except:
            print(f"Error formatting signal message: {e}")
        return f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù… Ø³ÛŒÚ¯Ù†Ø§Ù„ {symbol}/{currency}"

# =========================
# Ø³Ø§ÛŒØ± ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# =========================

def generate_random_string(length: int = 8, 
                         use_uppercase: bool = True,
                         use_lowercase: bool = True, 
                         use_digits: bool = True,
                         use_special: bool = False) -> str:
    """ØªÙˆÙ„ÛŒØ¯ Ø±Ø´ØªÙ‡ ØªØµØ§Ø¯ÙÛŒ"""
    chars = ""
    if use_uppercase:
        chars += string.ascii_uppercase
    if use_lowercase:
        chars += string.ascii_lowercase
    if use_digits:
        chars += string.digits
    if use_special:
        chars += "!@#$%^&*"
    
    if not chars:
        chars = string.ascii_letters + string.digits
    
    return ''.join(secrets.choice(chars) for _ in range(length))

def generate_referral_code(length: int = 8) -> str:
    """ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ø±ÙØ±Ø§Ù„"""
    return generate_random_string(length, use_lowercase=False, use_special=False)

def generate_transaction_id() -> str:
    """ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ØªØ±Ø§Ú©Ù†Ø´"""
    timestamp = str(int(time.time()))
    random_part = generate_random_string(6, use_lowercase=False)
    return f"TXN{timestamp}{random_part}"

def hash_string(text: str, salt: str = "") -> str:
    """Ù‡Ø´ Ú©Ø±Ø¯Ù† Ø±Ø´ØªÙ‡ Ø¨Ø§ SHA256"""
    combined = f"{text}{salt}"
    return hashlib.sha256(combined.encode('utf-8')).hexdigest()

def mask_sensitive_data(data: str, 
                       show_first: int = 2, 
                       show_last: int = 2, 
                       mask_char: str = "*") -> str:
    """Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³"""
    if len(data) <= show_first + show_last:
        return mask_char * len(data)
    
    masked_length = len(data) - show_first - show_last
    return f"{data[:show_first]}{mask_char * masked_length}{data[-show_last:]}"

def format_number(number: Union[int, float], 
                 decimal_places: int = 2,
                 use_comma: bool = True) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø¹Ø¯Ø§Ø¯"""
    if isinstance(number, int):
        formatted = f"{number:,}" if use_comma else str(number)
    else:
        formatted = f"{number:,.{decimal_places}f}" if use_comma else f"{number:.{decimal_places}f}"
    
    return formatted

def format_currency(amount: float, 
                   currency: str = "USD",
                   decimal_places: int = 2) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø±Ø²"""
    formatted_amount = format_number(amount, decimal_places)
    
    currency_symbols = {
        "USD": "$",
        "EUR": "â‚¬",
        "GBP": "Â£",
        "IRR": "Ø±ÛŒØ§Ù„",
        "USDT": "USDT",
        "BTC": "â‚¿"
    }
    
    symbol = currency_symbols.get(currency, currency)
    
    if currency in ["IRR"]:
        return f"{formatted_amount} {symbol}"
    else:
        return f"{symbol}{formatted_amount}"

def format_percentage(value: float, decimal_places: int = 2) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø±ØµØ¯"""
    return f"{value:.{decimal_places}f}%"

def format_time_delta(delta: timedelta) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯Øª Ø²Ù…Ø§Ù†"""
    total_seconds = int(delta.total_seconds())
    
    if total_seconds < 60:
        return f"{total_seconds} Ø«Ø§Ù†ÛŒÙ‡"
    elif total_seconds < 3600:
        minutes = total_seconds // 60
        return f"{minutes} Ø¯Ù‚ÛŒÙ‚Ù‡"
    elif total_seconds < 86400:
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        if minutes > 0:
            return f"{hours} Ø³Ø§Ø¹Øª Ùˆ {minutes} Ø¯Ù‚ÛŒÙ‚Ù‡"
        return f"{hours} Ø³Ø§Ø¹Øª"
    else:
        days = total_seconds // 86400
        hours = (total_seconds % 86400) // 3600
        if hours > 0:
            return f"{days} Ø±ÙˆØ² Ùˆ {hours} Ø³Ø§Ø¹Øª"
        return f"{days} Ø±ÙˆØ²"

def parse_user_input(text: str) -> Dict[str, Any]:
    """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    result = {
        "original": text,
        "cleaned": text.strip(),
        "words": text.strip().split(),
        "numbers": re.findall(r'\d+\.?\d*', text),
        "urls": re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)
    }
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø±Ø²
    symbols = re.findall(r'\b[A-Z]{2,10}\b', text.upper())
    result["symbols"] = list(set(symbols))
    
    return result

def safe_dict_get(dictionary: Dict[str, Any], 
                 key_path: str, 
                 default: Any = None) -> Any:
    """Ø¯Ø±ÛŒØ§ÙØª Ø§Ù…Ù† Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ù…Ø³ÛŒØ± Ú©Ù„ÛŒØ¯"""
    keys = key_path.split('.')
    current = dictionary
    
    try:
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        return current
    except (KeyError, TypeError):
        return default

def deep_merge_dicts(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:
    """ØªØ±Ú©ÛŒØ¨ Ø¹Ù…ÛŒÙ‚ Ø¯Ùˆ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ"""
    result = dict1.copy()
    
    for key, value in dict2.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge_dicts(result[key], value)
        else:
            result[key] = value
    
    return result

def clean_html_tags(text: str) -> str:
    """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML"""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def escape_markdown(text: str) -> str:
    """Escape Ú©Ø±Ø¯Ù† Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Markdown"""
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    for char in escape_chars:
        text = text.replace(char, f'\\{char}')
    return text

def truncate_text(text: str, 
                 max_length: int = 100, 
                 suffix: str = "...") -> str:
    """Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ†"""
    if len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """ØªÙ‚Ø³ÛŒÙ… Ù„ÛŒØ³Øª Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ú©ÙˆÚ†Ú©ØªØ±"""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª ØªÙˆØ¯Ø±ØªÙˆ Ø¨Ù‡ Ù„ÛŒØ³Øª Ø³Ø§Ø¯Ù‡"""
    return [item for sublist in nested_list for item in sublist]

def remove_duplicates(lst: List[Any], key_func=None) -> List[Any]:
    """Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø² Ù„ÛŒØ³Øª"""
    if key_func:
        seen = set()
        result = []
        for item in lst:
            key = key_func(item)
            if key not in seen:
                seen.add(key)
                result.append(item)
        return result
    else:
        return list(dict.fromkeys(lst))

def calculate_percentage_change(old_value: float, new_value: float) -> float:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±"""
    if old_value == 0:
        return 0.0
    return ((new_value - old_value) / old_value) * 100

def calculate_moving_average(values: List[float], window: int) -> List[float]:
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ØªØ­Ø±Ú©"""
    if len(values) < window:
        return []
    
    result = []
    for i in range(window - 1, len(values)):
        avg = sum(values[i - window + 1:i + 1]) / window
        result.append(avg)
    
    return result

def retry_on_failure(max_retries: int = 3, 
                    delay: float = 1.0,
                    exponential_backoff: bool = True):
    """Ø¯Ú©ÙˆØ±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    
                    wait_time = delay * (2 ** attempt if exponential_backoff else 1)
                    await asyncio.sleep(wait_time)
            
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    
                    wait_time = delay * (2 ** attempt if exponential_backoff else 1)
                    time.sleep(wait_time)
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

def rate_limit(calls_per_minute: int = 60):
    """Ø¯Ú©ÙˆØ±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù†Ø±Ø® ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ"""
    min_interval = 60.0 / calls_per_minute
    last_called = [0.0]
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            left_to_wait = min_interval - elapsed
            
            if left_to_wait > 0:
                time.sleep(left_to_wait)
            
            ret = func(*args, **kwargs)
            last_called[0] = time.time()
            return ret
        
        return wrapper
    return decorator

def memoize(maxsize: int = 128, ttl: int = 300):
    """Ø¯Ú©ÙˆØ±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ cache Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬"""
    def decorator(func):
        cache = {}
        cache_times = {}
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ cache
            key = str(args) + str(sorted(kwargs.items()))
            current_time = time.time()
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø± cache Ùˆ Ø§Ù†Ù‚Ø¶Ø§
            if key in cache:
                if current_time - cache_times[key] < ttl:
                    return cache[key]
                else:
                    # Ø­Ø°Ù Ø¢ÛŒØªÙ… Ù…Ù†Ù‚Ø¶ÛŒ
                    del cache[key]
                    del cache_times[key]
            
            # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø§Ù†Ø¯Ø§Ø²Ù‡ cache
            if len(cache) >= maxsize:
                # Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¢ÛŒØªÙ…
                oldest_key = min(cache_times.keys(), key=lambda k: cache_times[k])
                del cache[oldest_key]
                del cache_times[oldest_key]
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡
            result = func(*args, **kwargs)
            cache[key] = result
            cache_times[key] = current_time
            
            return result
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ØªØ¯ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† cache
        wrapper.clear_cache = lambda: cache.clear() or cache_times.clear()
        wrapper.cache_info = lambda: {
            'size': len(cache),
            'maxsize': maxsize,
            'ttl': ttl,
            'hits': getattr(wrapper, '_hits', 0),
            'misses': getattr(wrapper, '_misses', 0)
        }
        
        return wrapper
    return decorator

class Timer:
    """Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø²Ù…Ø§Ù†"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
    
    def start(self):
        """Ø´Ø±ÙˆØ¹ ØªØ§ÛŒÙ…Ø±"""
        self.start_time = time.time()
        return self
    
    def stop(self):
        """Ù¾Ø§ÛŒØ§Ù† ØªØ§ÛŒÙ…Ø±"""
        self.end_time = time.time()
        return self
    
    def elapsed(self) -> float:
        """Ø²Ù…Ø§Ù† Ø³Ù¾Ø±ÛŒ Ø´Ø¯Ù‡"""
        if self.start_time is None:
            return 0.0
        
        end = self.end_time if self.end_time else time.time()
        return end - self.start_time
    
    def __enter__(self):
        return self.start()
    
    def __exit__(self, *args):
        self.stop()

class DataProcessor:
    """Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    
    @staticmethod
    def normalize_data(data: List[float], 
                      min_val: float = 0.0, 
                      max_val: float = 1.0) -> List[float]:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        if not data:
            return []
        
        data_min = min(data)
        data_max = max(data)
        data_range = data_max - data_min
        
        if data_range == 0:
            return [min_val] * len(data)
        
        normalized = []
        for value in data:
            norm_val = (value - data_min) / data_range
            scaled_val = norm_val * (max_val - min_val) + min_val
            normalized.append(scaled_val)
        
        return normalized
    
    @staticmethod
    def calculate_statistics(data: List[float]) -> Dict[str, float]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ"""
        if not data:
            return {}
        
        sorted_data = sorted(data)
        n = len(data)
        
        mean = sum(data) / n
        median = sorted_data[n // 2] if n % 2 == 1 else (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
        
        variance = sum((x - mean) ** 2 for x in data) / n
        std_dev = variance ** 0.5
        
        return {
            'count': n,
            'mean': mean,
            'median': median,
            'min': min(data),
            'max': max(data),
            'variance': variance,
            'std_dev': std_dev,
            'range': max(data) - min(data)
        }
    
    @staticmethod
    def smooth_data(data: List[float], window_size: int = 3) -> List[float]:
        """Ù‡Ù…ÙˆØ§Ø± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        if len(data) < window_size:
            return data.copy()
        
        smoothed = []
        half_window = window_size // 2
        
        for i in range(len(data)):
            start = max(0, i - half_window)
            end = min(len(data), i + half_window + 1)
            smoothed.append(sum(data[start:end]) / (end - start))
        
        return smoothed

def convert_persian_numbers(text: str) -> str:
    """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ"""
    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
    english_digits = '0123456789'
    
    for persian, english in zip(persian_digits, english_digits):
        text = text.replace(persian, english)
    
    return text

def convert_english_numbers(text: str) -> str:
    """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
    english_digits = '0123456789'
    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
    
    for english, persian in zip(english_digits, persian_digits):
        text = text.replace(english, persian)
    
    return text

def create_progress_bar(current: int, 
                       total: int, 
                       length: int = 20,
                       fill_char: str = "â–ˆ",
                       empty_char: str = "â–‘") -> str:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª"""
    if total == 0:
        return empty_char * length
    
    percent = current / total
    filled_length = int(length * percent)
    
    bar = fill_char * filled_length + empty_char * (length - filled_length)
    return f"{bar} {percent:.1%}"